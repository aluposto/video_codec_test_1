# Patch top-level shim to return numpy array from get_encoded_stream(), then re-run test_video.py
from pathlib import Path
import os, sys, importlib, subprocess, traceback

repo_root = Path("/home/work/dcvc/DCVC_fresh").resolve()
os.chdir(repo_root)
sys.path.insert(0, str(repo_root))
os.environ["PYTHONPATH"] = str(repo_root)

shim_file = repo_root / "MLCodec_extensions_cpp.py"

shim = r'''
"""
Top-level shim implementing MLCodec_extensions_cpp API using the Python fallback.
Returns numpy arrays for byte streams so callers can call .tobytes().
"""

from src.python import mlcodec_rans_py as pyfb
import numpy as _np

class RansEncoder:
    def __init__(self):
        Impl = getattr(pyfb, "RansEncoder", None) or getattr(pyfb, "RansEncoderLib", None)
        if Impl is None:
            raise ImportError("No encoder implementation in Python fallback")
        self._impl = Impl()
        self._use_two = False

    def encode_y(self, symbols, cdf_group_index):
        arr = _np.asarray(symbols)
        if hasattr(self._impl, "encode_y"):
            return self._impl.encode_y(arr, int(cdf_group_index))
        raise AttributeError("Underlying encoder has no encode_y")

    def encode_z(self, symbols, cdf_group_index, start_offset, per_channel_size):
        arr = _np.asarray(symbols)
        if hasattr(self._impl, "encode_z"):
            return self._impl.encode_z(arr, int(cdf_group_index), int(start_offset), int(per_channel_size))
        raise AttributeError("Underlying encoder has no encode_z")

    def flush(self):
        if hasattr(self._impl, "flush"):
            return self._impl.flush()
        return None

    def get_encoded_stream(self):
        # Return a numpy ndarray of dtype uint8 so callers can use .tobytes()
        if hasattr(self._impl, "get_encoded_stream"):
            s = self._impl.get_encoded_stream()
            try:
                return _np.asarray(s, dtype=_np.uint8)
            except Exception:
                # if s is bytes/bytearray, convert
                try:
                    return _np.frombuffer(bytes(s), dtype=_np.uint8)
                except Exception:
                    return _np.array([], dtype=_np.uint8)
        return _np.array([], dtype=_np.uint8)

    def reset(self):
        if hasattr(self._impl, "reset"):
            return self._impl.reset()
        return None

    def add_cdf(self, cdfs, cdfs_sizes, offsets):
        return self._impl.add_cdf(cdfs, cdfs_sizes, offsets)

    def empty_cdf_buffer(self):
        if hasattr(self._impl, "empty_cdf_buffer"):
            return self._impl.empty_cdf_buffer()

    def set_use_two_encoders(self, b):
        if hasattr(self._impl, "set_use_two_encoders"):
            return self._impl.set_use_two_encoders(bool(b))
        self._use_two = bool(b)
        return None

    def get_use_two_encoders(self):
        if hasattr(self._impl, "get_use_two_encoders"):
            return bool(self._impl.get_use_two_encoders())
        return bool(self._use_two)


class RansDecoder:
    def __init__(self):
        Impl = getattr(pyfb, "RansDecoder", None) or getattr(pyfb, "RansDecoderLib", None)
        if Impl is None:
            raise ImportError("No decoder implementation in Python fallback")
        self._impl = Impl()
        self._use_two = False

    def set_stream(self, encoded):
        if isinstance(encoded, (bytes, bytearray)):
            if hasattr(self._impl, "set_stream"):
                try:
                    return self._impl.set_stream(encoded)
                except TypeError:
                    # some impls expect numpy arrays
                    import numpy as _np
                    return self._impl.set_stream(_np.frombuffer(bytes(encoded), dtype=_np.uint8))
        else:
            import numpy as _np
            arr = _np.asarray(encoded, dtype=_np.uint8)
            if hasattr(self._impl, "set_stream"):
                try:
                    return self._impl.set_stream(arr)
                except TypeError:
                    return self._impl.set_stream(arr.tobytes())
        if hasattr(self._impl, "_stream"):
            self._impl._stream = bytearray(encoded)

    def decode_y(self, indexes, cdf_group_index):
        if hasattr(self._impl, "decode_y"):
            return self._impl.decode_y(indexes, int(cdf_group_index))
        raise AttributeError("Underlying decoder has no decode_y")

    def decode_and_get_y(self, indexes, cdf_group_index):
        self.decode_y(indexes, cdf_group_index)
        return self.get_decoded_tensor()

    def decode_z(self, total_size, cdf_group_index, start_offset, per_channel_size):
        if hasattr(self._impl, "decode_z"):
            return self._impl.decode_z(int(total_size), int(cdf_group_index), int(start_offset), int(per_channel_size))
        # fallback: create zero array in underlying structure
        try:
            if hasattr(self._impl, "_decoded"):
                self._impl._decoded = [0] * int(total_size)
            elif hasattr(self._impl, "m_decoded"):
                self._impl.m_decoded = [0] * int(total_size)
            else:
                self._impl._decoded = [0] * int(total_size)
        except Exception:
            raise AttributeError("Underlying decoder has no decode_z and fallback failed")

    def get_decoded_tensor(self):
        if hasattr(self._impl, "get_decoded_tensor"):
            out = self._impl.get_decoded_tensor()
            import numpy as _np
            if isinstance(out, _np.ndarray):
                return out
            try:
                return _np.asarray(out)
            except Exception:
                return _np.array(list(out))
        import numpy as _np
        return _np.array([], dtype=_np.int16)

    def add_cdf(self, cdfs, cdfs_sizes, offsets):
        return self._impl.add_cdf(cdfs, cdfs_sizes, offsets)

    def empty_cdf_buffer(self):
        if hasattr(self._impl, "empty_cdf_buffer"):
            return self._impl.empty_cdf_buffer()

    def set_use_two_decoders(self, b):
        if hasattr(self._impl, "set_use_two_decoders"):
            return self._impl.set_use_two_decoders(bool(b))
        self._use_two = bool(b)

    def get_use_two_decoders(self):
        if hasattr(self._impl, "get_use_two_decoders"):
            return bool(self._impl.get_use_two_decoders())
        return bool(getattr(self, "_use_two", False))

pmf_to_quantized_cdf = getattr(pyfb, "pmf_to_quantized_cdf", None)
'''

# Write shim
shim_file.write_text(shim)
print("Patched shim written:", shim_file)

# Force reload and quick import check
importlib.invalidate_caches()
try:
    mod = importlib.import_module("MLCodec_extensions_cpp")
    print("Imported MLCodec_extensions_cpp shim OK:", mod)
except Exception:
    traceback.print_exc()

# Run the full command (same as you requested). If you prefer a shorter run, change --force_frame_num below.
cmd = [
    sys.executable, "test_video.py",
    "--model_path_i", "./checkpoints/cvpr2025_image.pth.tar",
    "--model_path_p", "./checkpoints/cvpr2025_video.pth.tar",
    "--rate_num", "4",
    "--test_config", "./dataset_config_example_yuv420.json",
    "--cuda", "1",
    "-w", "1",
    "--write_stream", "1",
    "--save_decoded_frame", "1",
    "--force_zero_thres", "0.12",
    "--output_path", "output.json",
    "--force_intra_period", "-1",
    "--reset_interval", "64",
    "--force_frame_num", "-1",   # full run; change to "2" for quick check
    "--check_existing", "0",
    "--verbose", "1",
]

print("Running test_video.py (full run requested) ...")
env = os.environ.copy()
env["PYTHONPATH"] = str(repo_root)
proc = subprocess.run(cmd, cwd=str(repo_root), env=env)
print("Return code:", proc.returncode)



Patched shim written: /home/work/dcvc/DCVC_fresh/MLCodec_extensions_cpp.py
Imported MLCodec_extensions_cpp shim OK: <module 'MLCodec_extensions_cpp' from '/home/work/dcvc/DCVC_fresh/MLCodec_extensions_cpp.py'>
Running test_video.py (full run requested) ...
cannot import cuda implementation for inference, fallback to pytorch.
testing 4 rates, using qp: 0, 21, 42, 63, 
  0%|          | 0/212 [00:00<?, ?it/s]
cannot import cuda implementation for inference, fallback to pytorch.
/pytorch/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:163: operator(): block: [440,0,0], thread: [33,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && "scatter gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:163: operator(): block: [440,0,0], thread: [35,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && "scatter gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:163: operator(): block: [440,0,0], thread: [37,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && "scatter gather kernel index out of bounds"` failed.
/pytorch/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:163: operator(): block: [440,0,0], thread: [39,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && "scatter gather kernel index out of bounds"` failed.
  0%|          | 0/212 [01:10<?, ?it/s]
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/work/dcvc/miniconda3/envs/dcvc_rt_env/lib/python3.12/concurrent/futures/process.py", line 264, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/work/dcvc/DCVC_fresh/test_video.py", line 370, in worker
    result = run_one_point_with_stream(p_frame_net, i_frame_net, args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/work/dcvc/DCVC_fresh/test_video.py", line 279, in run_one_point_with_stream
    decoded = i_frame_net.decompress(bit_stream, sps, qp)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/work/dcvc/DCVC_fresh/src/models/image_model.py", line 203, in decompress
    y_hat = self.decompress_prior_4x(params, self.y_spatial_prior_reduction,
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/work/dcvc/DCVC_fresh/src/models/common_model.py", line 276, in decompress_prior_4x
    y_q_r = self.gaussian_encoder.decode_and_get_y(scales_r, dtype, device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/work/dcvc/DCVC_fresh/src/models/entropy_models.py", line 323, in decode_and_get_y
    indexes, skip_cond = self.build_indexes_decoder(scales)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/work/dcvc/DCVC_fresh/src/models/entropy_models.py", line 294, in build_indexes_decoder
    indexes = indexes[skip_cond]
              ~~~~~~~^^^^^^^^^^^
torch.AcceleratorError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/work/dcvc/DCVC_fresh/test_video.py", line 541, in <module>
    main()
  File "/home/work/dcvc/DCVC_fresh/test_video.py", line 514, in main
    result = obj.result()
             ^^^^^^^^^^^^
  File "/home/work/dcvc/miniconda3/envs/dcvc_rt_env/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/home/work/dcvc/miniconda3/envs/dcvc_rt_env/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
torch.AcceleratorError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Return code: 1
