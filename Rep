Thanks — this is a useful error. The CUDA message

torch.AcceleratorError: CUDA error: device-side assert triggered
...
/pytorch/.../ScatterGatherKernel.cu:163 ... "scatter gather kernel index out of bounds"

means a GPU kernel saw an out-of-bounds index or otherwise invalid indexing. That usually comes from a tensor containing unexpected values (e.g. an index < 0 or >= size). It can be caused by:

a bug in the model / runtime (rare if using the official code),

mismatched shapes / dtypes / values produced by our Python fallback shim (likely, since we replaced the compiled entropy coder),

bad input data, or

a genuine hardware/driver mismatch (less likely given the message).


We need to narrow it down. I prepared three immediate steps you can run from the notebook. Run them in order and paste the outputs if the issue remains — I’ll use that to debug further.


---

1) Run on GPU with CUDA synchronous launching to get accurate stack trace

This forces CUDA calls to be synchronous so Python shows the exact failing line. Run one notebook cell:

# Cell: re-run test_video.py with CUDA_LAUNCH_BLOCKING=1 to get precise error location
import os, sys, subprocess
from pathlib import Path

repo_root = Path("/home/work/dcvc/DCVC_fresh").resolve()
os.chdir(repo_root)

env = os.environ.copy()
env["PYTHONPATH"] = str(repo_root)
env["CUDA_LAUNCH_BLOCKING"] = "1"

cmd = [
    sys.executable, "test_video.py",
    "--model_path_i", "./checkpoints/cvpr2025_image.pth.tar",
    "--model_path_p", "./checkpoints/cvpr2025_video.pth.tar",
    "--rate_num", "4",
    "--test_config", "./dataset_config_example_yuv420.json",
    "--cuda", "1",
    "-w", "1",
    "--write_stream", "1",
    "--save_decoded_frame", "0",
    "--force_zero_thres", "0.12",
    "--output_path", "output_debug_cuda.json",
    "--force_intra_period", "-1",
    "--reset_interval", "64",
    "--force_frame_num", "-1",
    "--check_existing", "0",
    "--verbose", "1",
]

print("Running with CUDA_LAUNCH_BLOCKING=1 ... (may produce big trace)")
proc = subprocess.run(cmd, cwd=str(repo_root), env=env, capture_output=True, text=True)
print("Returncode:", proc.returncode)
print("--- stdout (last 4000 chars) ---")
print(proc.stdout[-4000:])
print("--- stderr (last 4000 chars) ---")
print(proc.stderr[-4000:])

Why: this will show the exact Python line that triggered the GPU assert. Paste the stderr output if it still fails.


---

2) Run the same job on CPU to test whether the logic error reproduces without GPU

If the bug is due to wrong values from our Python entropy fallback, it will likely reproduce on CPU too — and the CPU stack traces are easier to read and debug.

Change --cuda to 0 and run:

# Cell: run full test on CPU (this may be slow). Use a small frame count if you want quick check.
import os, sys, subprocess
from pathlib import Path

repo_root = Path("/home/work/dcvc/DCVC_fresh").resolve()
os.chdir(repo_root)

env = os.environ.copy()
env["PYTHONPATH"] = str(repo_root)

cmd = [
    sys.executable, "test_video.py",
    "--model_path_i", "./checkpoints/cvpr2025_image.pth.tar",
    "--model_path_p", "./checkpoints/cvpr2025_video.pth.tar",
    "--rate_num", "4",
    "--test_config", "./dataset_config_example_yuv420.json",
    "--cuda", "0",
    "-w", "1",
    "--write_stream", "1",
    "--save_decoded_frame", "0",
    "--force_zero_thres", "0.12",
    "--output_path", "output_debug_cpu.json",
    "--force_intra_period", "-1",
    "--reset_interval", "64",
    "--force_frame_num", "2",   # small number to make this quick; set -1 for full run
    "--check_existing", "0",
    "--verbose", "1",
]

print("Running on CPU (2 frames) ...")
proc = subprocess.run(cmd, cwd=str(repo_root), env=env, capture_output=True, text=True)
print("Returncode:", proc.returncode)
print("--- stdout ---")
print(proc.stdout)
print("--- stderr ---")
print(proc.stderr)

If the CPU run errors similarly, share the trace. If CPU runs cleanly, the problem is GPU-specific (indexing may overflow due to dtype/casting differences on the GPU).


---

3) Quick inspect: verify that the fallback entropy coder returns reasonable index ranges / shapes

Because the kernel complained about "scatter gather index out of bounds", a common cause is an indexes tensor that contains values >= the cdf length. We can add a small check in the Python fallback to print max/min values of indexes or cdf before the failing op — but rather than changing dozens of files, run this helper to import the Python fallback and sample a few internal values from a small forward pass.

Run this cell to import the Python fallback and call the functions used earlier in the pipeline on a tiny synthetic input — this helps check index ranges produced by build_indexes_decoder etc. (I will attempt a conservative call that matches the code path, but if it errors paste the exception):

# Cell: quick sanity-check of entropy fallback internals (best-effort)
import importlib, numpy as np, traceback
from pathlib import Path
repo_root = Path("/home/work/dcvc/DCVC_fresh").resolve()
import sys
sys.path.insert(0, str(repo_root))

try:
    mod = importlib.import_module("src.python.mlcodec_rans_py")
    print("Imported src.python.mlcodec_rans_py OK")
except Exception:
    traceback.print_exc()
    raise SystemExit("Cannot import fallback module")

# Attempt to create entropy model object if available and inspect internals
try:
    # Try to find any class that looks like a decoder/encoder
    Enc = getattr(mod, "RansEncoder", None) or getattr(mod, "RansEncoderLib", None)
    Dec = getattr(mod, "RansDecoder", None) or getattr(mod, "RansDecoderLib", None)
    print("Enc:", Enc, "Dec:", Dec)
    if Enc is None or Dec is None:
        print("Fallback module lacks encoder/decoder classes; cannot inspect more.")
    else:
        enc = Enc()
        dec = Dec()
        # If available, examine add_cdf API signature with a small toy CDF:
        toy_cdf = np.array([[0, 819, 4096]], dtype=np.int32)  # shape (1,3)
        cdf_sizes = np.array([3], dtype=np.int32)
        offsets = np.array([0], dtype=np.int32)
        try:
            idx = enc.add_cdf(toy_cdf, cdf_sizes, offsets)
            print("add_cdf returned index:", idx)
        except Exception:
            traceback.print_exc()
            print("add_cdf failed on toy input.")
except Exception:
    traceback.print_exc()


---

Immediate recommended next actions (pick what you want)

1. Run Step 1 (CUDA_LAUNCH_BLOCKING=1) — this will give the exact Python line causing the kernel assert. Paste the stderr here. That’s the fastest way to find the root cause.


2. If CUDA stacktrace is noisy, run Step 2 (CPU small run) — if the CPU reproduces the bug we can debug with normal Python stack traces.


3. If we confirm it’s the Python fallback causing incorrect index ranges, the long-term fix is:

Build the real C++ extension in a separate conda env (recommended python 3.10 or 3.11) so MLCodec_extensions_cpp is the compiled extension. I’ll give exact commands for your CUDA/cuDNN/torch combination if you tell me torch.__version__ and cuda reported by nvidia-smi or torch.version.cuda.

OR thoroughly fix the Python fallback implementation to match the exact behaviors and numeric ranges of the C++ extension (harder but possible).



4. If you prefer immediate continuity and want to continue full runs now, you can try running with --cuda 0 (CPU) for the full dataset — it will likely run slower but may avoid the GPU assert if the CPU code path is safe.




---

Tell me which debug step you want me to run now (I recommend Step 1). If you want me to give the exact build commands for the C++ extension instead, say “Give build instructions” and I’ll produce a concise step-by-step conda recipe tuned to your environment.

