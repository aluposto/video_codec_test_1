Great — here are three ready-to-run notebook cells (one after another). They do:

1. Quick environment & import checks (makes sure src.layers.cuda_inference is importable).


2. Check PyTorch/CUDA availability.


3. Run test_video.py in a subprocess with PYTHONPATH correctly set so worker processes inherit it.



Run them in order (each in its own cell). Paste the outputs if anything errors and I’ll debug the next step.


---

Cell 1 — verify src.layers import and show repo layout

# Cell 1: verify importability of src.layers and list key files
from pathlib import Path
import importlib, os, sys, traceback

repo_root = Path("/home/work/dcvc/DCVC_fresh").resolve()
print("Repo root:", repo_root)
os.chdir(repo_root)

print("\nRepo listing (top-level):")
print([p.name for p in sorted(repo_root.iterdir()) if p.exists()])

print("\nChecking src and src/layers presence:")
print("src exists:", (repo_root / "src").exists())
print("src/layers exists:", (repo_root / "src" / "layers").exists())

# Attempt import with repo root on sys.path (for the notebook process)
sys.path.insert(0, str(repo_root))
try:
    m = importlib.import_module("src.layers.cuda_inference")
    print("\nImported src.layers.cuda_inference OK:", m)
except Exception as e:
    print("\nImport failed for src.layers.cuda_inference:")
    traceback.print_exc()
    # Show files under src/layers to help diagnose
    layers_dir = repo_root / "src" / "layers"
    if layers_dir.exists():
        print("\nFiles in src/layers:")
        for p in sorted(layers_dir.iterdir()):
            print(" ", p.name)
    else:
        print("\nsrc/layers not found on disk.")


---

Cell 2 — check PyTorch + CUDA status

# Cell 2: check torch and CUDA availability from notebook env
import torch, sys
print("Python:", sys.version.splitlines()[0])
print("torch:", getattr(torch, "__version__", "<not installed>"))
print("cuda available:", torch.cuda.is_available())
try:
    print("cuda device count:", torch.cuda.device_count())
    if torch.cuda.is_available() and torch.cuda.device_count()>0:
        print("current device index:", torch.cuda.current_device())
        print("device name:", torch.cuda.get_device_name(torch.cuda.current_device()))
except Exception as e:
    print("CUDA check error:", type(e).__name__, e)


---

Cell 3 — run test_video.py (subprocess) with PYTHONPATH set for subprocesses

> NOTE: this runs the full command you specified earlier with --cuda 1. If you don’t have a functional GPU (torch.cuda.is_available() was False), change "--cuda", "1" to "--cuda", "0" in the cmd list below before running.



# Cell 3: run test_video.py with PYTHONPATH set for the subprocess
import os, sys, subprocess
from pathlib import Path

repo_root = Path("/home/work/dcvc/DCVC_fresh").resolve()
os.chdir(repo_root)

env = os.environ.copy()
env["PYTHONPATH"] = str(repo_root)   # ensures worker subprocesses can import src.*

cmd = [
    sys.executable, "test_video.py",
    "--model_path_i", "./checkpoints/cvpr2025_image.pth.tar",
    "--model_path_p", "./checkpoints/cvpr2025_video.pth.tar",
    "--rate_num", "4",
    "--test_config", "./dataset_config_example_yuv420.json",
    "--cuda", "1",         # change to "0" if you don't have usable GPU
    "-w", "1",
    "--write_stream", "1",
    "--save_decoded_frame", "1",
    "--force_zero_thres", "0.12",
    "--output_path", "output.json",
    "--force_intra_period", "-1",
    "--reset_interval", "64",
    "--force_frame_num", "-1",
    "--check_existing", "0",
    "--verbose", "1",
]

print("Running:", " ".join(cmd))
proc = subprocess.run(cmd, cwd=str(repo_root), env=env)
print("Return code:", proc.returncode)


---

If you want the notebook to run the full job on CPU instead, edit the third cell: change the "--cuda", "1" token pair to "--cuda", "0" before running.

Run Cell 1 and Cell 2 first — if either shows an error (especially Cell 1 import error or Cell 2 shows CUDA unavailable while you expect a GPU), paste that output and I’ll give the exact next fix (guard, environment tweak, or GPU troubleshooting).

